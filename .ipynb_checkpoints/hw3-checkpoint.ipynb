{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98816da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a098a60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "0               0.00               0.64           0.64           0.0   \n",
       "1               0.21               0.28           0.50           0.0   \n",
       "2               0.06               0.00           0.71           0.0   \n",
       "3               0.00               0.00           0.00           0.0   \n",
       "4               0.00               0.00           0.00           0.0   \n",
       "...              ...                ...            ...           ...   \n",
       "4596            0.31               0.00           0.62           0.0   \n",
       "4597            0.00               0.00           0.00           0.0   \n",
       "4598            0.30               0.00           0.30           0.0   \n",
       "4599            0.96               0.00           0.00           0.0   \n",
       "4600            0.00               0.00           0.65           0.0   \n",
       "\n",
       "      word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "0              0.32            0.00              0.00                0.00   \n",
       "1              0.14            0.28              0.21                0.07   \n",
       "2              1.23            0.19              0.19                0.12   \n",
       "3              0.63            0.00              0.31                0.63   \n",
       "4              0.63            0.00              0.31                0.63   \n",
       "...             ...             ...               ...                 ...   \n",
       "4596           0.00            0.31              0.00                0.00   \n",
       "4597           0.00            0.00              0.00                0.00   \n",
       "4598           0.00            0.00              0.00                0.00   \n",
       "4599           0.32            0.00              0.00                0.00   \n",
       "4600           0.00            0.00              0.00                0.00   \n",
       "\n",
       "      word_freq_order  word_freq_mail  ...  char_freq_;   char_freq_(   \\\n",
       "0                0.00            0.00  ...         0.000         0.000   \n",
       "1                0.00            0.94  ...         0.000         0.132   \n",
       "2                0.64            0.25  ...         0.010         0.143   \n",
       "3                0.31            0.63  ...         0.000         0.137   \n",
       "4                0.31            0.63  ...         0.000         0.135   \n",
       "...               ...             ...  ...           ...           ...   \n",
       "4596             0.00            0.00  ...         0.000         0.232   \n",
       "4597             0.00            0.00  ...         0.000         0.000   \n",
       "4598             0.00            0.00  ...         0.102         0.718   \n",
       "4599             0.00            0.00  ...         0.000         0.057   \n",
       "4600             0.00            0.00  ...         0.000         0.000   \n",
       "\n",
       "      char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
       "0             0.0        0.778        0.000        0.000   \n",
       "1             0.0        0.372        0.180        0.048   \n",
       "2             0.0        0.276        0.184        0.010   \n",
       "3             0.0        0.137        0.000        0.000   \n",
       "4             0.0        0.135        0.000        0.000   \n",
       "...           ...          ...          ...          ...   \n",
       "4596          0.0        0.000        0.000        0.000   \n",
       "4597          0.0        0.353        0.000        0.000   \n",
       "4598          0.0        0.000        0.000        0.000   \n",
       "4599          0.0        0.000        0.000        0.000   \n",
       "4600          0.0        0.125        0.000        0.000   \n",
       "\n",
       "      capital_run_length_average  capital_run_length_longest  \\\n",
       "0                          3.756                          61   \n",
       "1                          5.114                         101   \n",
       "2                          9.821                         485   \n",
       "3                          3.537                          40   \n",
       "4                          3.537                          40   \n",
       "...                          ...                         ...   \n",
       "4596                       1.142                           3   \n",
       "4597                       1.555                           4   \n",
       "4598                       1.404                           6   \n",
       "4599                       1.147                           5   \n",
       "4600                       1.250                           5   \n",
       "\n",
       "      capital_run_length_total  spam  \n",
       "0                          278     1  \n",
       "1                         1028     1  \n",
       "2                         2259     1  \n",
       "3                          191     1  \n",
       "4                          191     1  \n",
       "...                        ...   ...  \n",
       "4596                        88     0  \n",
       "4597                        14     0  \n",
       "4598                       118     0  \n",
       "4599                        78     0  \n",
       "4600                        40     0  \n",
       "\n",
       "[4601 rows x 58 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['word_freq_make','word_freq_address', 'word_freq_all','word_freq_3d','word_freq_our','word_freq_over',\n",
    "         'word_freq_remove','word_freq_internet','word_freq_order','word_freq_mail','word_freq_receive','word_freq_will',\n",
    "         'word_freq_people','word_freq_report','word_freq_addresses','word_freq_free','word_freq_business','word_freq_email',\n",
    "         'word_freq_you','word_freq_credit','word_freq_your','word_freq_font','word_freq_000','word_freq_money','word_freq_hp',\n",
    "         'word_freq_hpl','word_freq_george','word_freq_650','word_freq_lab','word_freq_labs','word_freq_telnet','word_freq_857',\n",
    "         'word_freq_data','word_freq_415','word_freq_85','word_freq_technology','word_freq_1999','word_freq_parts','word_freq_pm',\n",
    "         'word_freq_direct','word_freq_cs','word_freq_meeting','word_freq_original','word_freq_project','word_freq_re','word_freq_edu',\n",
    "         'word_freq_table','word_freq_conference','char_freq_; ','char_freq_( ','char_freq_[','char_freq_!','char_freq_$','char_freq_#',\n",
    "        'capital_run_length_average','capital_run_length_longest','capital_run_length_total', 'spam']\n",
    "df = pd.read_csv('spambase.data', names=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a7a85b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "features = df.loc[:,df.columns != 'spam']\n",
    "target = df.loc[:, 'spam']\n",
    "# Split into training/testing\n",
    "# The following will split as 75% training 25% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.25, random_state=3000)\n",
    "scaler = StandardScaler()\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.transform(x_test), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a3c8c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a number based on its magnitude\n",
    "# If <= 100000, print using :.3f\n",
    "# Else print using :.0e\n",
    "def format_nbr(f):\n",
    "    if abs(f) < 100000:\n",
    "        return f'{f:.3f}'\n",
    "    else:\n",
    "        return f'{f:.4e}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9c09c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "y_test_predicted = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "186b81ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   confusion matrix =\n",
      " [[669  33]\n",
      " [ 44 405]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#1a conf matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_predicted)\n",
    "print(f'   confusion matrix =\\n {conf_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a67e447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives =  405,\n",
      "false positives = 33,\n",
      "true negatives = 669,\n",
      "false negatives = 44\n"
     ]
    }
   ],
   "source": [
    "#1a tn, fp, fn, tp\n",
    "tn, fp, fn, tp = conf_matrix.ravel() \n",
    "print (f'true positives =  {tp},\\nfalse positives = {fp},\\ntrue negatives = {tn},\\nfalse negatives = {fn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6211e957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy = 0.933\n",
      "   error = 0.067\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#1a acc/error \n",
    "acc = accuracy_score(y_test, y_test_predicted)\n",
    "err = 1-acc\n",
    "print(f'   accuracy = {format_nbr(acc)}')\n",
    "print(f'   error = {format_nbr(err)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "867cc0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#1a prec, recall, f1\n",
    "prec= precision_score(y_test, y_test_predicted)\n",
    "recall = recall_score(y_test, y_test_predicted)\n",
    "f1 = f1_score(y_test, y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea334b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       feature      Coef\n",
      "55  capital_run_length_longest  1.267732\n",
      "52                 char_freq_$  1.207775\n",
      "6             word_freq_remove  0.895562\n",
      "22               word_freq_000  0.894307\n",
      "3                 word_freq_3d  0.864112\n",
      "53                 char_freq_#  0.858514\n",
      "15              word_freq_free  0.821593\n",
      "19            word_freq_credit  0.569852\n",
      "56    capital_run_length_total  0.443533\n",
      "4                word_freq_our  0.396171\n",
      "16          word_freq_business  0.386323\n",
      "23             word_freq_money  0.361201\n",
      "35        word_freq_technology  0.290619\n",
      "51                 char_freq_!  0.248957\n",
      "27               word_freq_650  0.238475\n",
      "20              word_freq_your  0.237265\n",
      "21              word_freq_font  0.227725\n",
      "5               word_freq_over  0.191943\n",
      "7           word_freq_internet  0.191727\n",
      "8              word_freq_order  0.178446\n",
      "31               word_freq_857  0.162189\n",
      "18               word_freq_you  0.161183\n",
      "14         word_freq_addresses  0.132030\n",
      "17             word_freq_email  0.096326\n",
      "2                word_freq_all  0.077128\n",
      "13            word_freq_report  0.066924\n",
      "9               word_freq_mail  0.062902\n",
      "36              word_freq_1999  0.002406\n",
      "10           word_freq_receive -0.017561\n",
      "12            word_freq_people -0.022277\n",
      "0               word_freq_make -0.062459\n",
      "50                 char_freq_[ -0.069315\n",
      "49                char_freq_(  -0.119270\n",
      "37             word_freq_parts -0.131000\n",
      "11              word_freq_will -0.142506\n",
      "46             word_freq_table -0.178525\n",
      "1            word_freq_address -0.216185\n",
      "29              word_freq_labs -0.236895\n",
      "39            word_freq_direct -0.238364\n",
      "42          word_freq_original -0.287974\n",
      "48                char_freq_;  -0.309355\n",
      "54  capital_run_length_average -0.328625\n",
      "30            word_freq_telnet -0.370172\n",
      "38                word_freq_pm -0.413348\n",
      "32              word_freq_data -0.497956\n",
      "44                word_freq_re -0.732016\n",
      "47        word_freq_conference -0.810440\n",
      "25               word_freq_hpl -0.897575\n",
      "43           word_freq_project -0.925207\n",
      "45               word_freq_edu -1.169913\n",
      "33               word_freq_415 -1.207919\n",
      "34                word_freq_85 -1.251728\n",
      "41           word_freq_meeting -1.297299\n",
      "28               word_freq_lab -1.359462\n",
      "40                word_freq_cs -1.655612\n",
      "24                word_freq_hp -2.277950\n",
      "26            word_freq_george -3.912352\n"
     ]
    }
   ],
   "source": [
    "#1b print coeffs \n",
    "# Make a dataframe with first column naming features and 2nd column the coefficient for that feature\n",
    "d = {'feature': cols[:-1], 'Coef': log_model.coef_[0]}\n",
    "df_coef = pd.DataFrame(data = d)\n",
    "# Sort the coefficient dataframe to see which are largest (both positive and negative)\n",
    "df_coef_sorted = df_coef.sort_values('Coef', ascending=False)\n",
    "print(df_coef_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "461e0c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>0.818702</td>\n",
       "      <td>0.955457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.933102</td>\n",
       "      <td>0.924658</td>\n",
       "      <td>0.902004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.893136</td>\n",
       "      <td>0.945355</td>\n",
       "      <td>0.770601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.839270</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.605791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T  Accuracy  Precision   Recall:\n",
       "0  0.25  0.900087   0.818702  0.955457\n",
       "1  0.50  0.933102   0.924658  0.902004\n",
       "2  0.75  0.893136   0.945355  0.770601\n",
       "3  0.90  0.839270   0.971429  0.605791"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1c\n",
    "probs = log_model.predict_proba(X_test)\n",
    "col_t = []\n",
    "col_acc = []\n",
    "col_prec = []\n",
    "col_recall = []\n",
    "for t in [0.25, 0.5, 0.75, 0.9]:\n",
    "    y_pred_t = np.where(probs[:, 1] >= t, 1, 0)\n",
    "    accuracy = accuracy_score(y_test, y_pred_t)\n",
    "    prec= precision_score(y_test, y_pred_t)\n",
    "    recall = recall_score(y_test, y_pred_t)\n",
    "    col_t.append(t)\n",
    "    col_acc.append(accuracy)\n",
    "    col_prec.append(prec)\n",
    "    col_recall.append(recall)\n",
    "    \n",
    "d = {'T': col_t, 'Accuracy': col_acc, 'Precision': col_prec, 'Recall:' : col_recall}\n",
    "metrics_df = pd.DataFrame(d)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78119ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 gradient descent\n",
    "from numpy.linalg import norm\n",
    "class LogisticRegressionGD:\n",
    "    def __init__(self, alpha, epsilon = .01, max_iter=1000):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "        self.theta_ = []\n",
    "       \n",
    "    def loss(self, h, y):\n",
    "        h = np.maximum(h, 1.0e-9)\n",
    "        h = np.minimum(h, 1 - 1.0e-9)\n",
    "        return - (y @ np.log(h) + (1 - y)@np.log(1 - h))\n",
    "    \n",
    "    # fits the model to the training data\n",
    "    def fit(self, X, y):\n",
    "        X_arr = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        # Initialize random theta\n",
    "        self.theta_ = np.random.rand(X_arr.shape[1])\n",
    "       \n",
    "        for i in range(0, self.max_iter):\n",
    "            z = X_arr @ self.theta_\n",
    "            z = np.maximum(-1.0E2, z)\n",
    "            h = 1 / (1 + np.exp(-z))\n",
    "            self.cross_entropy_loss = self.loss(h, y)\n",
    "            theta_new = self.theta_ - self.alpha * (h - y).transpose() @ X_arr\n",
    "            delta = np.linalg.norm(theta_new - self.theta_)\n",
    "            self.theta_ = theta_new\n",
    "            if delta < self.epsilon:\n",
    "                break\n",
    "        # Save instance variables used by run_model method\n",
    "        self.coef_ = self.theta_[1:]\n",
    "        self.intercept_ = self.theta_[0]\n",
    "\n",
    "    # Predict Y values given X values using model fit\n",
    "    def predict(self, X):\n",
    "        X2 = np.insert(X.to_numpy(), 0, 1, axis=1)\n",
    "        probs = X2 @ self.theta_\n",
    "        result = np.where(probs >= 0.5, 1, 0)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8dca74c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>10</td>\n",
       "      <td>2555.730836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1129.407017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>916.694472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>10</td>\n",
       "      <td>930.822418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>50</td>\n",
       "      <td>782.442702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>100</td>\n",
       "      <td>753.978324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>10</td>\n",
       "      <td>1334.152174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>50</td>\n",
       "      <td>1580.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>100</td>\n",
       "      <td>1541.236654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning Rate  Iterations         Loss\n",
       "0         0.0001          10  2555.730836\n",
       "1         0.0001          50  1129.407017\n",
       "2         0.0001         100   916.694472\n",
       "3         0.0010          10   930.822418\n",
       "4         0.0010          50   782.442702\n",
       "5         0.0010         100   753.978324\n",
       "6         0.0100          10  1334.152174\n",
       "7         0.0100          50  1580.657400\n",
       "8         0.0100         100  1541.236654"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "lr_col = []\n",
    "iter_col = []\n",
    "loss_col = []\n",
    "for alpha in [.0001, .001, .01]:\n",
    "    for max_iter in [10, 50, 100]:\n",
    "        model = LogisticRegressionGD(alpha = alpha, max_iter = max_iter)\n",
    "        model.fit(X_train, y_train)\n",
    "        lr_col.append(alpha)\n",
    "        iter_col.append(max_iter)\n",
    "        loss_col.append(model.cross_entropy_loss)\n",
    "        #print(f'Iterations: {max_iter}, Learning rate: {alpha}, Cross-entropy loss: {model.cross_entropy_loss:.4f}')\n",
    "        \n",
    "d = {'Learning Rate': lr_col, 'Iterations': iter_col, 'Loss': loss_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "360f233f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall:</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.904431</td>\n",
       "      <td>0.916462</td>\n",
       "      <td>0.830735</td>\n",
       "      <td>0.871495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.919201</td>\n",
       "      <td>0.929952</td>\n",
       "      <td>0.857461</td>\n",
       "      <td>0.892236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.925282</td>\n",
       "      <td>0.885350</td>\n",
       "      <td>0.928731</td>\n",
       "      <td>0.906522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.900956</td>\n",
       "      <td>0.820268</td>\n",
       "      <td>0.955457</td>\n",
       "      <td>0.882716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  Accuracy  Precision   Recall:        F1\n",
       "0  0.0001  0.904431   0.916462  0.830735  0.871495\n",
       "1  0.0010  0.919201   0.929952  0.857461  0.892236\n",
       "2  0.0050  0.925282   0.885350  0.928731  0.906522\n",
       "3  0.0100  0.900956   0.820268  0.955457  0.882716"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "# Report metrics after 100 iterations with varying learning rates\n",
    "\n",
    "col_alpha = []\n",
    "col_acc = []\n",
    "col_prec = []\n",
    "col_recall = []\n",
    "col_f1 = []\n",
    "for alpha in [.0001, .001, .005, .01]:\n",
    "    model = LogisticRegressionGD(alpha = alpha, max_iter = 100)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_test_predicted)\n",
    "    recall = recall_score(y_test, y_test_predicted)\n",
    "    f1 = f1_score(y_test, y_test_predicted)\n",
    "    col_alpha.append(alpha)\n",
    "    col_acc.append(accuracy)\n",
    "    col_prec.append(precision)\n",
    "    col_recall.append(recall)\n",
    "    col_f1.append(f1)\n",
    "    \n",
    "d = {'alpha': col_alpha, 'Accuracy': col_acc, 'Precision': col_prec, 'Recall:' : col_recall, 'F1': col_f1}\n",
    "metrics_df = pd.DataFrame(d)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c6b884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 5}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.901449</td>\n",
       "      <td>0.098551</td>\n",
       "      <td>0.878587</td>\n",
       "      <td>0.871698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.905217</td>\n",
       "      <td>0.094783</td>\n",
       "      <td>0.888749</td>\n",
       "      <td>0.869479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0.902899</td>\n",
       "      <td>0.097101</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>0.862896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.904348</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.896071</td>\n",
       "      <td>0.858484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.900870</td>\n",
       "      <td>0.099130</td>\n",
       "      <td>0.895463</td>\n",
       "      <td>0.848963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>0.896522</td>\n",
       "      <td>0.103478</td>\n",
       "      <td>0.900072</td>\n",
       "      <td>0.830632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k  accuracy     error  precision    recall\n",
       "0   3  0.901449  0.098551   0.878587  0.871698\n",
       "1   5  0.905217  0.094783   0.888749  0.869479\n",
       "2   7  0.902899  0.097101   0.889114  0.862896\n",
       "3   9  0.904348  0.095652   0.896071  0.858484\n",
       "4  11  0.900870  0.099130   0.895463  0.848963\n",
       "5  15  0.896522  0.103478   0.900072  0.830632"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3a\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "k_vals = [3,5,7,9,11,15]\n",
    "grid_parameters = { 'n_neighbors': k_vals}  # which parameters should be tested\n",
    "gridsearch_cv = GridSearchCV(KNeighborsClassifier(), grid_parameters, scoring=['accuracy', 'precision', 'recall'], refit='accuracy', cv=5)\n",
    "gridsearch_cv.fit(x_train, y_train)\n",
    "print(gridsearch_cv.best_params_)  # This tells you the best parameter choice\n",
    "# Create data for making a DataFrame for displaying results\n",
    "d = {'k': k_vals,\n",
    "     'accuracy': gridsearch_cv.cv_results_['mean_test_accuracy'],\n",
    "     'error': 1-gridsearch_cv.cv_results_['mean_test_accuracy'],\n",
    "     'precision': gridsearch_cv.cv_results_['mean_test_precision'],\n",
    "     'recall': gridsearch_cv.cv_results_['mean_test_recall']}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9820dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.932174</td>\n",
       "      <td>0.918519</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kNN</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>0.890187</td>\n",
       "      <td>0.848552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.928116</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.933102</td>\n",
       "      <td>0.924658</td>\n",
       "      <td>0.902004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Training</td>\n",
       "      <td>0.885507</td>\n",
       "      <td>0.918755</td>\n",
       "      <td>0.779326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Testing</td>\n",
       "      <td>0.894005</td>\n",
       "      <td>0.916031</td>\n",
       "      <td>0.801782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model      Data  Accuracy  Precision    Recall\n",
       "0                  kNN  Training  0.932174   0.918519  0.909091\n",
       "1                  kNN   Testing  0.900087   0.890187  0.848552\n",
       "2  Logistic Regression  Training  0.928116   0.928571  0.886364\n",
       "3  Logistic Regression   Testing  0.933102   0.924658  0.902004\n",
       "4                  LDA  Training  0.885507   0.918755  0.779326\n",
       "5                  LDA   Testing  0.894005   0.916031  0.801782"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3b\n",
    "model_col = []\n",
    "data_col = []\n",
    "acc_col = []\n",
    "prec_col = []\n",
    "recall_col = []\n",
    "estimators = {'kNN' : KNeighborsClassifier(n_neighbors=5),\n",
    "              'Logistic Regression': LogisticRegression(),\n",
    "             'LDA': LinearDiscriminantAnalysis() }\n",
    "for name, model in estimators.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    for (data_name, data_x, data_y) in [('Training', X_train, y_train), ('Testing', X_test, y_test)]:\n",
    "        y_pred = model.predict(data_x)\n",
    "        accuracy = accuracy_score(data_y, y_pred)\n",
    "        precision = precision_score(data_y, y_pred)\n",
    "        recall = recall_score(data_y, y_pred)\n",
    "        f1 = f1_score(data_y, y_pred)\n",
    "        model_col.append(name)\n",
    "        data_col.append(data_name)\n",
    "        acc_col.append(accuracy)\n",
    "        prec_col.append(precision)\n",
    "        recall_col.append(recall)\n",
    "        \n",
    "d = {'Model': model_col, 'Data': data_col, 'Accuracy': acc_col, 'Precision': prec_col, 'Recall': recall_col}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84da4519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3c\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "probs = log_model.predict_proba(X_test)\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test, probs[:,1])\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc, estimator_name='auc')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f97b9d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3d\n",
    "from sklearn.metrics import recall_score\n",
    "fprs = []\n",
    "tprs = []\n",
    "\n",
    "model = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "probs = model.predict_proba(X_test)\n",
    "for t in np.arange(0, 1.01, .005):\n",
    "    y_pred_t = np.where(probs[:, 1] >= t, 1, 0)\n",
    "    tpr = recall_score(y_test, y_pred)\n",
    "    fpr = 1 - recall_score(y_test, y_pred, pos_label = 0)\n",
    "    fprs.append(fpr)\n",
    "    tprs.append(tpr)\n",
    "plt.plot(fprs, tprs)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da7780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import kfold\n",
    "\n",
    "\n",
    "#4a\n",
    "ave_err = 0\n",
    "def kfold_cv(splits, X_data, y_data)\n",
    "    count = 0\n",
    "    err_col = []\n",
    "    exp_col = []\n",
    "    kf = KFold(n_splits=splits)\n",
    "    kf.get_n_splits(X_data)\n",
    "    for train_index, test_index in kf.split(X_data):\n",
    "        x_train_kf = x_train.iloc[train_index]\n",
    "        x_test_kf = x_train.iloc[test_index]\n",
    "        y_train_kf = y[train_index]\n",
    "        y_test_kf = y[test_index]\n",
    "        model = KNearestNeighbors()\n",
    "        model.fit(x_train_kf, x_test_kf)\n",
    "        y_pred_kf = model.predict(x_test_kf)\n",
    "        acc = accuracy_score(y_test, y_pred_kf)\n",
    "        err = 1 - acc\n",
    "        ave_err += err\n",
    "        err_col.append(err)\n",
    "        exp_col.append(count)\n",
    "        count += 1\n",
    "    ave_err = ave_err/splits\n",
    "    print ('average error: ' ave_err)\n",
    "    d = {'experiment': exp_col, 'error': err_col}\n",
    "    return pd.DataFrame(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
